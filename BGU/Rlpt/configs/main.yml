
cost_sniffer:
  gui: true
  save_costs: false

gui:
  render_ee_icons: true
  render_trajectory_lines: true

episode_plots:
  show: true

agent:
  model: # The Neural network 
    load_checkpoint: false
    save_checkpoints: true
    checkpoint_path: None # 'BGU/Rlpt/trained_models/2025:01:03(Fri)22:13:25/model.pth'
    dst_dir: 'BGU/Rlpt/trained_models'
    include_etl: true
    state_representation: # input layer 
      robot_dofs_positions: true
      robot_dofs_velocities: true
      goal_pose: true
      coll_objs: false
      robot_base_pos: false
      prev_action_idx: false
      pi_mppi_means: true
      pi_mppi_covs: true

      
  train_suit:
    gamma: 1
    batch_size: 128
    grad_clipping: false

  reward:
    goal_pos_thresh_dist: 0.01 # activation radius. meters
    goal_rot_thresh_dist: 0.01 # meters
    col_thresh_dist: 0.05 # meters
    time_reward: linear # (or fixed)
    pose_reward: false # false means no direct reward on goal state, learning just from time to goal and collisions
    safety_w: 100
    pose_w: 10
    step_dur_w: 1
    terminal_collision: true
    terminal_goal: true




  training:
    n_episodes: 1000
    max_ts: 150
    disable_frequent_h_changing: false
    sample_objs_every_episode: false
    sample_obj_locs_every_episode: false
    sample_goal_every_episode: true
    reset_to_initial_state_every_episode: false
    default_goal_pose: [-0.37, -0.37, 0.3, 0, 2.5, 0, 1] # storm coordinates



    

